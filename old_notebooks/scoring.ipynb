{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0aabf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from typing import Dict, List, Any, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731236f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RuleBasedScoringEngine:\n",
    "    \"\"\"\n",
    "    A deterministic rule-based scoring engine that applies traditional palmistry rules\n",
    "    to generate quantitative scores based on textual descriptions.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, rule_config: Dict[str, Any] = None):\n",
    "        self.rules = rule_config or self._get_default_rules()\n",
    "        \n",
    "\n",
    "    def _get_default_rules(self) -> Dict[str, List]:\n",
    "        \"\"\"Define default palmistry rules based on traditional knowledge.\"\"\"\n",
    "        return {\n",
    "            \"life_line_rules\": [\n",
    "                {\"condition\": \"long and curved\", \"scores\": {\"strength\": 0.8, \"romantic\": 0.6, \"luck\": 0.7, \"potential\": 0.9}},\n",
    "                {\"condition\": \"short and straight\", \"scores\": {\"strength\": 0.4, \"romantic\": 0.3, \"luck\": 0.5, \"potential\": 0.6}},\n",
    "                {\"condition\": \"deep and clear\", \"scores\": {\"strength\": 0.9, \"romantic\": 0.7, \"luck\": 0.8, \"potential\": 0.8}},\n",
    "                {\"condition\": \"faint and broken\", \"scores\": {\"strength\": 0.3, \"romantic\": 0.4, \"luck\": 0.2, \"potential\": 0.4}}\n",
    "            ],\n",
    "            \"heart_line_rules\": [\n",
    "                {\"condition\": \"long and curved\", \"scores\": {\"strength\": 0.6, \"romantic\": 0.9, \"luck\": 0.7, \"potential\": 0.7}},\n",
    "                {\"condition\": \"straight and short\", \"scores\": {\"strength\": 0.7, \"romantic\": 0.4, \"luck\": 0.6, \"potential\": 0.5}},\n",
    "                {\"condition\": \"deep and clear\", \"scores\": {\"strength\": 0.8, \"romantic\": 0.8, \"luck\": 0.7, \"potential\": 0.8}},\n",
    "                {\"condition\": \"chain-like\", \"scores\": {\"strength\": 0.5, \"romantic\": 0.9, \"luck\": 0.6, \"potential\": 0.6}}\n",
    "            ],\n",
    "            \"head_line_rules\": [\n",
    "                {\"condition\": \"long and straight\", \"scores\": {\"strength\": 0.7, \"romantic\": 0.5, \"luck\": 0.6, \"potential\": 0.9}},\n",
    "                {\"condition\": \"short and curved\", \"scores\": {\"strength\": 0.5, \"romantic\": 0.7, \"luck\": 0.5, \"potential\": 0.6}},\n",
    "                {\"condition\": \"deep and clear\", \"scores\": {\"strength\": 0.8, \"romantic\": 0.6, \"luck\": 0.7, \"potential\": 0.8}},\n",
    "                {\"condition\": \"faint and wavy\", \"scores\": {\"strength\": 0.4, \"romantic\": 0.5, \"luck\": 0.4, \"potential\": 0.5}}\n",
    "            ],\n",
    "            \"fate_line_rules\": [\n",
    "                {\"condition\": \"present and clear\", \"scores\": {\"strength\": 0.7, \"romantic\": 0.6, \"luck\": 0.8, \"potential\": 0.8}},\n",
    "                {\"condition\": \"absent\", \"scores\": {\"strength\": 0.5, \"romantic\": 0.5, \"luck\": 0.5, \"potential\": 0.5}},\n",
    "                {\"condition\": \"deep and long\", \"scores\": {\"strength\": 0.8, \"romantic\": 0.7, \"luck\": 0.9, \"potential\": 0.9}},\n",
    "                {\"condition\": \"broken\", \"scores\": {\"strength\": 0.4, \"romantic\": 0.4, \"luck\": 0.3, \"potential\": 0.4}}\n",
    "            ]\n",
    "        }\n",
    "    \n",
    "\n",
    "    def parse_text_descriptions(self, text_description: str) -> Dict[str, str]:\n",
    "        \"\"\"\n",
    "        Parse the text description from the Text Decoder branch to extract line characteristics.\n",
    "        \"\"\"\n",
    "        characteristics = {}\n",
    "        lines = text_description.split(';')\n",
    "        for line in lines:\n",
    "            if ':' in line:\n",
    "                key, value = line.split(':', 1)\n",
    "                characteristics[key.strip()] = value.strip()\n",
    "        return characteristics\n",
    "    \n",
    "\n",
    "    def apply_rules(self, characteristics: Dict[str, str]) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Apply rules based on the extracted characteristics to generate scores.\n",
    "        \"\"\"\n",
    "        scores = {\"strength\": 0.0, \"romantic\": 0.0, \"luck\": 0.0, \"potential\": 0.0}\n",
    "        weights = {\"life_line\": 0.3, \"heart_line\": 0.3, \"head_line\": 0.25, \"fate_line\": 0.15}\n",
    "        rule_count = {key: 0 for key in scores.keys()}\n",
    "        \n",
    "        for line_type, description in characteristics.items():\n",
    "            if line_type in self.rules and description:\n",
    "                line_rules = self.rules[line_type]\n",
    "                weight = weights.get(line_type, 0.2)\n",
    "                \n",
    "                for rule in line_rules:\n",
    "                    if rule[\"condition\"] in description.lower():\n",
    "                        for score_type, score_value in rule[\"scores\"].items():\n",
    "                            scores[score_type] += score_value * weight\n",
    "                            rule_count[score_type] += 1\n",
    "        \n",
    "        # normalize scores by rule count\n",
    "        for score_type in scores:\n",
    "            if rule_count[score_type] > 0:\n",
    "                scores[score_type] = min(1.0, scores[score_type] / rule_count[score_type])\n",
    "            else:\n",
    "                scores[score_type] = 0.5  # default neutral score\n",
    "        \n",
    "        return scores\n",
    "    \n",
    "    \n",
    "    def calculate_scores(self, text_description: str) -> Dict[str, float]:\n",
    "        \"\"\"Main method to calculate rule-based scores from text descriptions.\"\"\"\n",
    "        characteristics = self.parse_text_descriptions(text_description)\n",
    "        return self.apply_rules(characteristics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ea8f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PalmistryScorePredictor(nn.Module):\n",
    "    \"\"\"\n",
    "    Neural network for predicting palmistry scores from unified embeddings.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, embedding_dim: int = 512, hidden_dims: List[int] = None):\n",
    "        super(PalmistryScorePredictor, self).__init__()\n",
    "        self.hidden_dims = hidden_dims or [256, 128, 64]\n",
    "        \n",
    "        layers = []\n",
    "        input_dim = embedding_dim\n",
    "        \n",
    "        for hidden_dim in self.hidden_dims:\n",
    "            layers.extend([\n",
    "                nn.Linear(input_dim, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.3),\n",
    "                nn.BatchNorm1d(hidden_dim)\n",
    "            ])\n",
    "            input_dim = hidden_dim\n",
    "        \n",
    "        layers.append(nn.Linear(input_dim, 4))  # 4 scores: \"strength\", \"romantic\", \"luck\", \"potential\"\n",
    "        layers.append(nn.Sigmoid())             # sigmoid to control range to be [0, 1]\n",
    "        \n",
    "        self.network = nn.Sequential(*layers)\n",
    "    \n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdbecfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetworkScorePredictor:\n",
    "    \"\"\"\n",
    "    A shallow neural network that predicts scores from unified embeddings.\n",
    "    Correlates with rule-based scores while learning non-linear patterns.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, embedding_dim: int = 512, hidden_dims: List[int] = None):\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.model = PalmistryScorePredictor(embedding_dim, hidden_dims)\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=0.001)\n",
    "        \n",
    "\n",
    "    def train(self, embeddings: np.ndarray, rule_scores: np.ndarray, \n",
    "              validation_data: Tuple = None, epochs: int = 100, \n",
    "              batch_size: int = 32) -> Dict[str, List[float]]:\n",
    "        \"\"\"\n",
    "        Train the neural network to predict scores that correlate with rule-based scores.\n",
    "        \"\"\"\n",
    "\n",
    "        X_train = torch.FloatTensor(embeddings)\n",
    "        y_train = torch.FloatTensor(rule_scores)\n",
    "        \n",
    "        dataset = TensorDataset(X_train, y_train)\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "        self.model.train()\n",
    "        \n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            epoch_loss = 0.0\n",
    "            for batch_X, batch_y in dataloader:\n",
    "                self.optimizer.zero_grad()\n",
    "                \n",
    "                # forward pass\n",
    "                outputs = self.model(batch_X)\n",
    "                loss = self.criterion(outputs, batch_y)\n",
    "                \n",
    "                # backward pass\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                epoch_loss += loss.item()\n",
    "            \n",
    "            avg_train_loss = epoch_loss / len(dataloader)\n",
    "            train_losses.append(avg_train_loss)\n",
    "            \n",
    "            # Validation if validation data provided\n",
    "            if validation_data is not None:\n",
    "                val_loss = self.evaluate(validation_data[0], validation_data[1])\n",
    "                val_losses.append(val_loss)\n",
    "                \n",
    "                if epoch % 10 == 0:\n",
    "                    print(f'Epoch [{epoch+1}/{epochs}], Train Loss: {avg_train_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
    "            else:\n",
    "                if epoch % 10 == 0:\n",
    "                    print(f'Epoch [{epoch+1}/{epochs}], Train Loss: {avg_train_loss:.4f}')\n",
    "        \n",
    "        return {'train_loss': train_losses, 'val_loss': val_losses}\n",
    "    \n",
    "\n",
    "    def evaluate(self, X_val: np.ndarray, y_val: np.ndarray) -> float:\n",
    "        \"\"\"Evaluate the model on validation data.\"\"\"\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            X_val_tensor = torch.FloatTensor(X_val)\n",
    "            y_val_tensor = torch.FloatTensor(y_val)\n",
    "            outputs = self.model(X_val_tensor)\n",
    "            loss = self.criterion(outputs, y_val_tensor)\n",
    "        self.model.train()\n",
    "        return loss.item()\n",
    "    \n",
    "    \n",
    "    def predict_scores(self, embedding: np.ndarray) -> Dict[str, float]:\n",
    "        \"\"\"Predict scores from a single embedding vector.\"\"\"\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Ensure correct input format\n",
    "        if isinstance(embedding, np.ndarray):\n",
    "            embedding = torch.FloatTensor(embedding)\n",
    "        \n",
    "        if len(embedding.shape) == 1:\n",
    "            embedding = embedding.unsqueeze(0)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            predictions = self.model(embedding)\n",
    "            scores_array = predictions[0].numpy()  # first prediction\n",
    "        \n",
    "        return {\n",
    "            \"strength\": float(scores_array[0]),\n",
    "            \"romantic\": float(scores_array[1]),\n",
    "            \"luck\": float(scores_array[2]),\n",
    "            \"potential\": float(scores_array[3])\n",
    "        }\n",
    "    \n",
    "\n",
    "    def save_model(self, filepath: str):\n",
    "        \"\"\"Save the trained model.\"\"\"\n",
    "        torch.save({\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'embedding_dim': self.embedding_dim\n",
    "        }, filepath)\n",
    "    \n",
    "\n",
    "    def load_model(self, filepath: str):\n",
    "        \"\"\"Load a pre-trained model.\"\"\"\n",
    "        checkpoint = torch.load(filepath)\n",
    "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1694cdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridScoringSystem:\n",
    "    \"\"\"\n",
    "    Combined system that integrates rule-based and neural network scoring approaches.\n",
    "    Provides final scores with configurable weighting between the two approaches.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, embedding_dim: int = 512, alpha: float = 0.7):\n",
    "        \"\"\"\n",
    "        Initialize the hybrid scoring system.\n",
    "        \n",
    "        args:\n",
    "        - embedding_dim: Dimension of the input embedding vector\n",
    "        - alpha: Weight for rule-based scores (1-alpha for neural network scores)\n",
    "        \"\"\"\n",
    "        self.rule_engine = RuleBasedScoringEngine()\n",
    "        self.nn_predictor = NeuralNetworkScorePredictor(embedding_dim=embedding_dim)\n",
    "        self.alpha = alpha\n",
    "    \n",
    "\n",
    "    def set_alpha(self, alpha: float):\n",
    "        \"\"\"Set the weighting parameter between rule-based and NN scores.\"\"\"\n",
    "        self.alpha = max(0.0, min(1.0, alpha))\n",
    "    \n",
    "\n",
    "    def calculate_final_scores(self, text_description: str, \n",
    "                              embedding: np.ndarray) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Calculate final scores by combining rule-based and neural network predictions.\n",
    "        \"\"\"\n",
    "        rule_scores = self.rule_engine.calculate_scores(text_description)   # rule-based scores\n",
    "        \n",
    "        nn_scores = self.nn_predictor.predict_scores(embedding)             # predicted scores from NN\n",
    "        \n",
    "        final_scores = {}\n",
    "        for key in rule_scores.keys():\n",
    "            rule_score = rule_scores[key]\n",
    "            nn_score = nn_scores[key]\n",
    "            final_scores[key] = (self.alpha * rule_score + \n",
    "                               (1 - self.alpha) * nn_score)                 # combines scores by weighted average\n",
    "        \n",
    "        return final_scores\n",
    "    \n",
    "\n",
    "    def get_detailed_breakdown(self, text_description: str, \n",
    "                             embedding: np.ndarray) -> Dict[str, Any]:\n",
    "        \"\"\"Get detailed scoring breakdown including individual components.\"\"\"\n",
    "        rule_scores = self.rule_engine.calculate_scores(text_description)\n",
    "        nn_scores = self.nn_predictor.predict_scores(embedding)\n",
    "        final_scores = self.calculate_final_scores(text_description, embedding)\n",
    "        \n",
    "        return {\n",
    "            \"rule_based_scores\": rule_scores,\n",
    "            \"neural_network_scores\": nn_scores,\n",
    "            \"final_scores\": final_scores,\n",
    "            \"weight_parameter\": self.alpha\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399ecc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    \"\"\"Example training function.\"\"\"\n",
    "    \n",
    "    embedding_dim = 512\n",
    "    predictor = NeuralNetworkScorePredictor(embedding_dim=embedding_dim)\n",
    "    \n",
    "    num_samples = 1000\n",
    "    X_train = np.random.randn(num_samples, embedding_dim).astype(np.float32)    # example: random data\n",
    "    \n",
    "    rule_scores = np.random.rand(num_samples, 4).astype(np.float32)             # example: random number as scores\n",
    "    \n",
    "    history = predictor.train(X_train, rule_scores, epochs=50, batch_size=32)\n",
    "    \n",
    "    print(\"Training completed!\")\n",
    "    return predictor, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a403ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_system():\n",
    "    \"\"\"Demonstrate the scoring system with example data.\"\"\"\n",
    "    \n",
    "    embedding_dim = 512\n",
    "    scoring_system = HybridScoringSystem(embedding_dim=embedding_dim)\n",
    "    \n",
    "    example_text = \"life_line: long and curved; heart_line: deep and clear; head_line: long and straight; fate_line: present and clear\"\n",
    "    \n",
    "    example_embedding = np.random.randn(embedding_dim).astype(np.float32)\n",
    "    \n",
    "    final_scores = scoring_system.calculate_final_scores(example_text, example_embedding)\n",
    "    \n",
    "    print(\"=== PALMISTRY SCORING SYSTEM RESULTS ===\")\n",
    "    print(\"\\nFinal Scores:\")\n",
    "    print(json.dumps(final_scores, indent=2, ensure_ascii=False))\n",
    "    \n",
    "    return final_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e664cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_scores = demonstrate_system()\n",
    "\n",
    "trained_predictor, training_history = train_model()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
